{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ecde5b-a777-4575-b85a-cdace8c5cdac",
   "metadata": {},
   "source": [
    "# Total Employment Trend in Franklin and Delaware Countires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9474f75-08e1-48e8-acfa-2a06268c5b89",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaabe2c-f4c5-4c5a-bc16-896fa9527eb4",
   "metadata": {},
   "source": [
    "This script is meant to take Quarterly Census of Employment and Wages data to filter for Franklin and Delaware Counties from 2010-2021, and create a new combined table and line graph to visualize the employment levels in both counties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bcaf4-5fc4-473f-b2fb-cb716d7fcacb",
   "metadata": {},
   "source": [
    "### Process Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87be89-32e4-44e3-af55-c451bee8e02f",
   "metadata": {},
   "source": [
    "The process carried out by this workflow can be described as follows:\n",
    "  - The script will retrieve the QCEW datasets from the US Bureau of Labor Statistics\n",
    "  - Filter to only retain and sum records from Franklin or Delawre, Ohio 2010-2021\n",
    "  - Identify and keep only the rows containing all industires and all coverage\n",
    "  - Write aggregated table and line chart to Excel to visualize the changes in employment levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf25f4-0682-4eb1-90ad-8fbd5ef70787",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a70168-ed69-48b8-940d-08e0566fd709",
   "metadata": {},
   "source": [
    "### Import required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb71c5b7-f061-4772-80ae-03573e131481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import urllib.request\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import json\n",
    "from tableschema import Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05530b6c-fd5c-483c-9a0e-b50051422c1a",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "903e357f-db12-4b5a-af04-c5ef65426180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "INPUT_DIR = \"./input_data\"\n",
    "OUTPUT_DIR = \"./output_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e6e88c-5a26-4cb0-9564-d236050ac351",
   "metadata": {},
   "source": [
    "### Define inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388abfe5-6d11-4984-9c66-9ca9da4b2cef",
   "metadata": {},
   "source": [
    "#### QCEW data for Franklin and Delaware Counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee66d1bf-dd1d-4f36-aee7-31cddafd0ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: ./input_data\\combined.csv\n",
      "Schema: ./input_data\\combined_schema.json\n"
     ]
    }
   ],
   "source": [
    "COMBINED_TABLE_FILENAME = \"combined.csv\"\n",
    "COMBINED_TABLE_PATH = os.path.join(INPUT_DIR, COMBINED_TABLE_FILENAME)\n",
    "COMBINED_TABLE_SCHEMA_FILENAME = COMBINED_TABLE_FILENAME.replace(\".csv\",\"_schema.json\")\n",
    "COMBINED_TABLE_SCHEMA_PATH = os.path.join(INPUT_DIR, COMBINED_TABLE_SCHEMA_FILENAME)\n",
    "print(\"Data: {}\".format(COMBINED_TABLE_PATH))\n",
    "print(\"Schema: {}\".format(COMBINED_TABLE_SCHEMA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37829d7b-1f22-4187-ad51-c742aaea9620",
   "metadata": {},
   "source": [
    "#### Complined Excel Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47cbfba9-4cb4-430b-b78a-9eac4a35754a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data path: ./output_data\\compiled.xlsx\n"
     ]
    }
   ],
   "source": [
    "EXCEL_TABLE_FILENAME = \"compiled.xlsx\"\n",
    "EXCEL_TABLE_PATH = os.path.join(OUTPUT_DIR, EXCEL_TABLE_FILENAME)\n",
    "print(\"Output data path: {}\".format(EXCEL_TABLE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399902a-7dfc-418c-b10a-f23d77f71e5b",
   "metadata": {},
   "source": [
    "### Define outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd177fc7-552b-42f0-b5b6-390f953e85c7",
   "metadata": {},
   "source": [
    "#### Franklin and Delaware counties employment level by year (2010-2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d22f07df-c42b-44bb-9d36-3c053e914656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: ./output_data\\annual_avg_emplvl.csv\n",
      "Schema: ./output_data\\annual_avg_emplvl_schema.json\n"
     ]
    }
   ],
   "source": [
    "EMPLVL_TABLE_FILENAME = \"annual_avg_emplvl.csv\"\n",
    "EMPLVL_TABLE_PATH = os.path.join(OUTPUT_DIR, EMPLVL_TABLE_FILENAME)\n",
    "EMPLVL_TABLE_SCHEMA_FILENAME = EMPLVL_TABLE_FILENAME.replace(\".csv\",\"_schema.json\")\n",
    "EMPLVL_TABLE_SCHEMA_PATH = os.path.join(OUTPUT_DIR, EMPLVL_TABLE_SCHEMA_FILENAME)\n",
    "print(\"Data: {}\".format(EMPLVL_TABLE_PATH))\n",
    "print(\"Schema: {}\".format(EMPLVL_TABLE_SCHEMA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fff3c-9945-4abc-8b6e-803ba431d4d2",
   "metadata": {},
   "source": [
    "## Getting input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6dd60c85-405d-45de-a6be-d1436f53debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2014...\n",
      "Fetching data for 2015...\n",
      "Fetching data for 2016...\n",
      "Fetching data for 2017...\n",
      "Fetching data for 2018...\n",
      "Fetching data for 2019...\n",
      "Fetching data for 2020...\n",
      "Fetching data for 2021...\n",
      "Fetching data for 2014...\n",
      "Fetching data for 2015...\n",
      "Fetching data for 2016...\n",
      "Fetching data for 2017...\n",
      "Fetching data for 2018...\n",
      "Fetching data for 2019...\n",
      "Fetching data for 2020...\n",
      "Fetching data for 2021...\n",
      "The CSV files have been combined and saved.\n",
      "Processed data saved to ./input_data\\combined.csv\n",
      "The data has been aggregated by year and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ogwynn\\AppData\\Local\\Temp\\ipykernel_11564\\3004708976.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['annual_avg_emplvl_thousands'] = filtered_df['annual_avg_emplvl'] / 1000\n"
     ]
    }
   ],
   "source": [
    "# *******************************************************************************\n",
    "# qcewCreateDataRows : This function takes a raw csv string and splits it into\n",
    "# a two-dimensional array containing the data and the header row of the csv file\n",
    "# a try/except block is used to handle for both binary and char encoding\n",
    "def qcewCreateDataRows(csv):\n",
    "    dataRows = []\n",
    "    try: dataLines = csv.decode().split('\\r\\n')\n",
    "    except er: dataLines = csv.split('\\r\\n');\n",
    "    for row in dataLines:\n",
    "        dataRows.append(row.split(','))\n",
    "    return dataRows\n",
    "# *******************************************************************************\n",
    "\n",
    "# *******************************************************************************\n",
    "# qcewGetAreaData : This function takes a year, quarter, and area argument and\n",
    "# returns an array containing the associated area data. Use 'a' for annual\n",
    "# averages. \n",
    "# For all area codes and titles see:\n",
    "# http://www.bls.gov/cew/doc/titles/area/area_titles.htm\n",
    "#\n",
    "def qcewGetAreaData(year,qtr,area):\n",
    "    urlPath = \"http://data.bls.gov/cew/data/api/[YEAR]/[QTR]/area/[AREA].csv\"\n",
    "    urlPath = urlPath.replace(\"[YEAR]\",year)\n",
    "    urlPath = urlPath.replace(\"[QTR]\",qtr.lower())\n",
    "    urlPath = urlPath.replace(\"[AREA]\",area.upper())\n",
    "    httpStream = urllib.request.urlopen(urlPath)\n",
    "    csv = httpStream.read()\n",
    "    httpStream.close()\n",
    "    return qcewCreateDataRows(csv)\n",
    "\n",
    "\n",
    "def fetch_and_combine_qcew_data(start_year, end_year, qtr, area):\n",
    "    all_years_data = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"Fetching data for {year}...\")\n",
    "        year_data = qcewGetAreaData(str(year), qtr, area)\n",
    "        columns_no_quotes = [col.replace('\"', '') for col in year_data[0]]\n",
    "        year_data_df = pd.DataFrame(year_data[1:], columns=columns_no_quotes)\n",
    "        # Add a column to distinguish data by year\n",
    "        year_data_df['year'] = year\n",
    "        # Remove every instance of \" in the data\n",
    "        year_data_df = year_data_df.replace('\"', '', regex=True)\n",
    "        all_years_data.append(year_data_df)\n",
    "        \n",
    "    # Combine all DataFrame objects into a single DataFrame\n",
    "    combined_df = pd.concat(all_years_data, ignore_index=True)\n",
    "    \n",
    "    # Apply filtering: retain rows where industry_code == \"10\" and own_code == \"0\"\n",
    "    filtered_df = combined_df.loc[(combined_df['industry_code'] == \"10\") & (combined_df['own_code'] == \"0\")]\n",
    "\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Fetch and combine the data\n",
    "combined_franklin_data = fetch_and_combine_qcew_data(2014, 2021, \"a\", \"39049\")\n",
    "\n",
    "# Fetch and combine the data\n",
    "combined_delaware_data = fetch_and_combine_qcew_data(2014, 2021, \"a\", \"39041\")\n",
    "\n",
    "# Combine the DataFrames\n",
    "combined_df = pd.concat([combined_franklin_data, combined_delaware_data], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(COMBINED_TABLE_PATH, index=False)\n",
    "\n",
    "print(\"The CSV files have been combined and saved.\")\n",
    "print(f\"Processed data saved to {COMBINED_TABLE_PATH}\")\n",
    "\n",
    "\n",
    "# Create table\n",
    "table = Table(COMBINED_TABLE_PATH)\n",
    "\n",
    "# Infer table variable types\n",
    "table.infer()\n",
    "\n",
    "# Convert missing values to 'N/A'\n",
    "table.schema.descriptor['missingValues'] = ['N/A', '']\n",
    "table.schema.commit()\n",
    "\n",
    "# Save schema\n",
    "table.schema.save(COMBINED_TABLE_SCHEMA_PATH)\n",
    "\n",
    "\n",
    "\n",
    "# Load the schema from the JSON file\n",
    "with open(COMBINED_TABLE_SCHEMA_PATH, 'r') as file:\n",
    "    schema = json.load(file)\n",
    "\n",
    "# Define a function to convert data types based on the schema\n",
    "def convert_data_types(row, schema):\n",
    "    converted_row = {}\n",
    "    for field in schema['fields']:\n",
    "        field_name = field['name']\n",
    "        field_type = field['type']\n",
    "        if field_name in row:\n",
    "            if field_type == 'int':\n",
    "                converted_row[field_name] = int(row[field_name])\n",
    "            elif field_type == 'string':\n",
    "                converted_row[field_name] = str(row[field_name])\n",
    "            # Add more type conversions as needed\n",
    "            else:\n",
    "                converted_row[field_name] = row[field_name]  # Keep as is if type not recognized\n",
    "    return converted_row\n",
    "\n",
    "# Read the input data, apply conversion, and process it\n",
    "converted_data = []\n",
    "\n",
    "with open(COMBINED_TABLE_PATH, 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        converted_row = convert_data_types(row, schema)\n",
    "        converted_data.append(converted_row)\n",
    "\n",
    "df = pd.read_csv(COMBINED_TABLE_PATH)\n",
    "df.head()\n",
    "\n",
    "# Aggregate rows by \"year\" and sum up all other numeric columns\n",
    "aggregated_df = df.groupby('year').sum().reset_index()\n",
    "\n",
    "aggregated_df.to_csv(COMBINED_TABLE_PATH, index=False)\n",
    "\n",
    "print(\"The data has been aggregated by year and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cc474-7f36-4b68-8443-aa9356c98512",
   "metadata": {},
   "source": [
    "## Formatting and fitlering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "69247632-7b19-4f8c-aaf3-0202c84e5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(COMBINED_TABLE_PATH)\n",
    "df.head()\n",
    "\n",
    "# Select only the 'year' and 'annual_avg_emplvl' columns\n",
    "data = df[['year', 'annual_avg_emplvl']]\n",
    "\n",
    "data.to_csv(EMPLVL_TABLE_PATH, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Create table\n",
    "table = Table(EMPLVL_TABLE_PATH)\n",
    "\n",
    "# Infer table variable types\n",
    "table.infer()\n",
    "\n",
    "# Convert missing values to 'N/A'\n",
    "table.schema.descriptor['missingValues'] = ['N/A', '']\n",
    "table.schema.commit()\n",
    "\n",
    "# Save schema\n",
    "table.schema.save(EMPLVL_TABLE_SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a17d5-8b2f-4e94-9fa4-d18fb046076a",
   "metadata": {},
   "source": [
    "## Dataset and graph to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e887833f-91f5-4e9b-b3f5-fb959faabdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file with line chart created successfully.\n"
     ]
    }
   ],
   "source": [
    "def create_line_chart_excel(df, excel_file_path):\n",
    "    with pd.ExcelWriter(excel_file_path, engine='xlsxwriter') as writer:\n",
    "        df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "        legend_label = 'Total Employment'\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "        \n",
    "        chart = workbook.add_chart({'type': 'line'})\n",
    "        \n",
    "        chart.add_series({\n",
    "            'name': legend_label,\n",
    "            'categories': '=Sheet1!$A$2:$A${}'.format(len(df) + 1),\n",
    "            'values': '=Sheet1!$C$2:$C${}'.format(len(df) + 1),\n",
    "        })\n",
    "        \n",
    "        # Set chart title with Arial font\n",
    "        chart.set_title({\n",
    "            'name': 'Total Employment Trend',\n",
    "            'name_font': {'name': 'Arial', 'size': 14}\n",
    "        })\n",
    "        \n",
    "        # Set x-axis with Arial font and remove tick marks and line\n",
    "        chart.set_x_axis({\n",
    "            'name': '',\n",
    "            'name_font': {'name': 'Arial', 'size': 8},  # Axis title font\n",
    "            'num_font': {'name': 'Arial', 'size': 8},   # Tick labels font\n",
    "            'major_tick_mark': 'none',\n",
    "            'line': {'none': True}\n",
    "        })\n",
    "        \n",
    "        # Set y-axis with Arial font and remove the line\n",
    "        chart.set_y_axis({\n",
    "            'name': 'Thousands',\n",
    "            'name_font': {'name': 'Arial', 'size': 8},  # Axis title font\n",
    "            'num_font': {'name': 'Arial', 'size': 8},   # Tick labels font\n",
    "            'major_gridlines': {\n",
    "            'visible': True, \n",
    "            'line': {'color': '#808080', 'width': 1}  # Medium gray color for major gridlines\n",
    "        },\n",
    "        'line': {'none': True}  # Remove y-axis line\n",
    "    })\n",
    "\n",
    "        chart.set_legend({'position': 'bottom', 'font': {'name': 'Arial', 'size': 10}})\n",
    "\n",
    "        # Insert the chart into the worksheet\n",
    "        worksheet.insert_chart('D2', chart)\n",
    "\n",
    "\n",
    "# Create the line chart in the Excel file\n",
    "create_line_chart_excel(filtered_df, EXCEL_TABLE_PATH)\n",
    "\n",
    "print(\"Excel file with line chart created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1962ca-f4c4-431c-a7ba-bb66bf501b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
